# CapStone_2024
This is the repo for our senior capstone, Generating Content using LLMs

# LangChain Documentation
https://python.langchain.com/docs/tutorials/rag/

# LLama 3.1 RAG Setup
1. Download Ollama from https://ollama.com/ follow instructions in applicaion
2. When prompted run "ollama pull llama3.1" instead of llama 3.2 in terminal
3. Ensure the Ollama server is running by opening Ollama application
4. Run "pip3 install -r requirements.txt"
5. Run "python3 llm.py" in the llama directory
6. Note: the application take a while to work so if you want to ensure its working open activity monior or task manager to see how much memory you are using